---
title: "A small review of univariate parametric statistics"
author:
  - name: Marguerite Butler
    url: https://butlerlab.org
    affiliation: School of Life Sciences, University of Hawaii
    affiliation_url: https://manoa.hawaii.edu/lifesciences/
description: "What regression and ANOVA mean when exploring data"
date: 2025-03-06
categories: [module 4, week 7, univariate, statistics, ggplot2, dplyr]
---

# Learning objectives

::: callout-note
# Learning objectives

**At the end of this lesson you will:**

-   Be able to perform basic univariate statistics
-   Be able to design plots to display univariate comparisons
-   Be able to relate questions to graphical representations of data
:::

# Overview

A small review of the linear regression and ANOVA


# Tiny review of Univariate statistics

## Linear Regression

Linear regression asks whether there is a relationship between X and Y, that is if you know X can you predict the value of Y?

```{r}
with(iris, plot(Sepal.Width ~ Sepal.Length))
lm.fit <- with(iris, lm(Sepal.Width ~ Sepal.Length))
abline(lm.fit, col="blue")
```

Linear regression results in two parameters, the best-fit slope and intercept:

```{r}
lm.fit 
summary(lm.fit)
```

Regression minimizes the __sum of squared errors__ (or deviations) from the line. The "errors" are the difference between where Y is, and where Y should be if it followed a perfect line. 

We can illustrate what this means:

```{r}
x <- iris$Sepal.Length
y <- iris$Sepal.Width
yhat <- predict(lm.fit)

with(iris, plot(Sepal.Width ~ Sepal.Length))
with(iris, abline(lm.fit, col="blue"))
for(i in 1:length(x))  lines(x[c(i,i)],c(y[i], yhat[i]), col="red", lty=2)
```

The regression line is the best fit line that minimizes the sums of squared deviations from the regression. It turns out that the least-squares fit of the regression line is also provides the Maximum Likelihood fits of the parameters of the line (the slope and intercept).

## ANOVA

Analysis of variance is very closely related to regression. It also works by minimizing sums of squares, but it asks a different question. 

Does the data better fit a model with one group (one regression line?) or multiple groups (multiple regression lines, one for each group)?

Graphically, it looks like the plot below with the question _Is the data explained better by a single group with a grand mean? or with separate means for each_ `Species`? 
 

```{r}
par(mfrow=c(1,2))
with(iris, boxplot(Sepal.Length))
with(iris, plot(Sepal.Length ~ Species))
```

### Is One of these Groups not like the others? 

Statistically, this is asking whether the sums of squares is minimized by assuming there is only one group (one mean)? Or three groups?

For this plot we will add an index column (1 to number of observations), and use `ggplot2`, `dplyr`, and the pipe from `magrittr`

```{r}
#| warning: false
require(dplyr)
require(magrittr)
require(ggplot2)

dat <- cbind(iris, id = 1:length(iris$Species))
yhat <- mean(iris$Sepal.Length)  # grand mean of Sepal Length

p <- dat %>% ggplot(aes( x = id, y = Sepal.Length, group=Species)) 

q <- p + geom_point( size=2) + 
  geom_hline( aes(yintercept = mean(iris$Sepal.Length)) ) + 
  geom_segment( data=dat, aes( x = id, y = Sepal.Length, xend = id, yend = yhat), color="red", lty = 3)

q  
```

We added two new ggplot2 functions:  

-   __geom_hline()__ which adds a horizontal line used for the grand mean. This is similar to base R `abline()`  
-   __geom_segment()__ which plots line segments indicated by x,y start points and xend,yend end points (this is based on the base R `segment()` function)  

To add in the group structure, we need to compute means by species, and know where one species ends and the other begins in the data vector. We can do this with `group_by()` and `summarize()`:

```{r}
spmeans  <- dat %>% group_by(Species) %>% 
        summarise(
          sl = mean(Sepal.Length),
          n = length(Sepal.Length),
          minid = min(id),
          maxid = max(id)
        )

spmeans
```

(You should always check that minid and maxid is what you intended)

We want to include this mean information in the dataframe, so to add it as a vector, we can `merge()`: 

```{r}
dat <- merge(dat, spmeans)
head(dat)
dat[45:55,]
tail(dat)
```

Now that we have our dataframe with all of the necessary information, we can plot. 

Note that there are two calls to `geom_segment()`. For the first, we are plotting the species means, so we use the smmeans dataset. For the second, we are plotting each pointʻs deviation from the species means so we use the full dataset.  The rest is telling the function where the start and end points of each segment are:

```{r}
r <- p + geom_point( size=2) + 
  geom_segment( data=spmeans, aes(x=minid, y = sl, xend=maxid, yend=sl, group=Species )) + 
  geom_segment( data=dat, aes( x = id, y = Sepal.Length, xend = id, yend = sl, color=Species), lty = 3) 

r  
```


Back to our question - is the error sum of squares minimized by accouting for separate species or considering all irises as one group? Another way to state ANOVA is - is at least one of these groups different than the others?

```{r}
require(cowplot)
plot_grid(
  q, 
  r + theme(legend.position="none"), 
  labels="AUTO")
```
If we want to know whether species are different in sepal length, then we need to have lm fit the model by species. We do this like so:

```{r}
lm.fit <- with(iris, lm(Sepal.Length ~ Species))
summary(lm.fit)
```

__Interpretation:__ One-way ANOVA is like fitting a regression of the individual points against the grand mean of the points vs. separate regressions for each group. The summary shows that the the intercept (the mean of setosa) is about 5 (significantly different than zero), whereas the other species are contrasts against setosa, the first species. Versicolor is 0.93 higher than setosa, and  virginica is 1.58 higher than setosa. Both of these contrasts are signficant. So they are actually all significantly different than each other


Notice that now have more parameters estimated. You can specify which parameter values and contrasts you want displayed. Often we just want an ANOVA table, which tests the hypothesis that __at least one group is different than the others__:

```{r}
anova(lm.fit)
``` 

We can see that species are significantly different in sepal length. Can you make a plot that shows this and add the statistics to it? 

_And thatʻs how ANOVA is related to regression!_ 


## ANCOVA

There are many forms of regession and ANOVA. For example, if you want to see if the relationship between Sepal.Length and Sepal.Width differs by species, you woul do an ANCOVA (analysis of covariance):

```{r}
lm.fit <- with(iris, lm(Sepal.Width ~ Sepal.Length + Species))
summary(lm.fit)
```

Which would fit separate Y-intercepts for each species. 

## Violin Plots

Violin plots are visually appealing for showing differences in mean ("location") as well as the distribution of points around them, and are easy to do with `ggplot2`. 

```{r}
library(ggplot2)
library(magrittr)

p <- iris %>% ggplot(aes(x=Species, y=Sepal.Length))
p + geom_violin()
```

If you want to add colors, use the `fill` aesthetic:

```{r}
p <- iris %>% ggplot(aes(x=Species, y=Sepal.Length, fill=Species))
p + geom_violin()
```

You can even overlay points (or add bar plots, etc.):

```{r}
p + 
  geom_violin() +
  geom_point()
```

Notice that you cannot see 50 points per species. Try geom_jitter().  Now notice that the jitter is really wide. Look up the help page for geom_jitter() and find how to customize the width of the jitter. 

You can find many more examples of beautiful graphs at <https://r-graph-gallery.com>


